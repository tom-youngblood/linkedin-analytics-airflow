name: Backup and Export

on:
  schedule:
    # Run backup daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:

jobs:
  backup-dags:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Create backup archive
      run: |
        mkdir -p backup
        cp -r dags/ backup/
        cp -r include/ backup/
        cp requirements.txt backup/
        cp Dockerfile backup/
        cp packages.txt backup/
        cp .astro/config.yaml backup/
        
        # Create timestamped backup
        timestamp=$(date +%Y%m%d_%H%M%S)
        tar -czf "airflow-backup-${timestamp}.tar.gz" backup/
        
        echo "Backup created: airflow-backup-${timestamp}.tar.gz"

    - name: Upload backup artifact
      uses: actions/upload-artifact@v3
      with:
        name: airflow-backup-${{ github.run_number }}
        path: airflow-backup-*.tar.gz
        retention-days: 90

    - name: Export to cloud storage (optional)
      run: |
        # Example: Upload to S3 for long-term storage
        # pip install boto3
        # aws s3 cp airflow-backup-*.tar.gz s3://your-backup-bucket/
        echo "Cloud backup would be uploaded here" 